{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "labeling_colab.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJQmydXvk88hUslPTvpxEW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zambbo/BERT-blog-sentiment-analysis/blob/master/labeling_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmICjr5klTG_"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Tqt2io3_lZMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0')"
      ],
      "metadata": {
        "id": "ZD1X51qHl4uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QoevfPkrl75g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 셋을 BERT모델에 알맞은 형태로 변경\n",
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "YmBpPasil9-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT 모델\n",
        "#sentiment predict를 위해서는 num_classes를 3으로 설정해준다\n",
        "#objective/subjective predict를 위해서는 num_classes를 2로 설정해준다.\n",
        "#default는 3으로 되어있다\n",
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=3,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "\n",
        "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "        \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "    \n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "\n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "metadata": {
        "id": "vlgEtnBg3SZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kobert import get_tokenizer\n",
        "from kobert import get_pytorch_kobert_model"
      ],
      "metadata": {
        "id": "rd_tWrVT3Uyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KoBERT 모델과 KoBERT vocabulary를 다운받는다.\n",
        "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")"
      ],
      "metadata": {
        "id": "Y0bJGjAP3ppc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_model = BERTClassifier(bertmodel, num_classes=3, dr_rate=0.5).to(device)\n",
        "subjective_model = BERTClassifier(bertmodel, num_classes=2, dr_rate=0.5).to(device)"
      ],
      "metadata": {
        "id": "HEMrx_O_3xks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_path = '/content/drive/MyDrive/dataset/sentiment_model.pt'\n",
        "subj_path = '/content/drive/MyDrive/dataset/subjetive_model.pt'"
      ],
      "metadata": {
        "id": "MM4w78uB37pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_model.load_state_dict(torch.load(sent_path))\n",
        "subjective_model.load_state_dict(torch.load(subj_path))"
      ],
      "metadata": {
        "id": "2fYW9Qjx4eUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_model.eval()\n",
        "subjective_model.eval()"
      ],
      "metadata": {
        "id": "Wp8d9ZpR4gbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "labeling_file_path = '/content/drive/MyDrive/dataset/미니어처.csv'\n",
        "df = pd.read_csv(labeling_file_path ,index_col=0)\n",
        "df.sample(3)"
      ],
      "metadata": {
        "id": "EeVISiVJ4k7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kss"
      ],
      "metadata": {
        "id": "GWvScUFY5M6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import re\n",
        "\n",
        "# def preprocessing_sentence(sentence):\n",
        "#     sent = re.sub(\"[^ ㄱ-ㅎ가-힣a-zA-Z0-9]\", \"\", sentence)\n",
        "#     return sent"
      ],
      "metadata": {
        "id": "Fw5fQqIL5TTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# posts = [preprocessing_sentence(post) for post in df['Post'].values]"
      ],
      "metadata": {
        "id": "t2zIozc05xhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import kss\n",
        "# post_sentences = []\n",
        "\n",
        "# for post in posts:\n",
        "#     sents = [sent for sent in kss.split_sentences(post)]\n",
        "#     post_sentences.append(sents)\n",
        "# post_sentences[0]"
      ],
      "metadata": {
        "id": "nH-LmRUJ54CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# after_labeling_file_path = '/content/drive/MyDrive/dataset/labeling_미니어처.txt'\n",
        "# with open(after_labeling_file_path,\"w\",encoding=\"utf-8\") as f:\n",
        "#     for sents in post_sentences:\n",
        "#         for sent in sents:\n",
        "#             f.write(f\"{sent}\\t1\\t1\\n\")"
      ],
      "metadata": {
        "id": "9Wb4B17W55MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prelabeling_data_file_path = '/content/drive/MyDrive/dataset/labeling_미니어처.txt'\n",
        "sentences = []\n",
        "df = pd.read_csv(prelabeling_data_file_path, sep='\\t', names=['sentence','sentiment','objective'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "jJrg-aYRolnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = df['sentence'].values"
      ],
      "metadata": {
        "id": "8FadNuPVo67n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 64\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ],
      "metadata": {
        "id": "Q8dd_ziLpVuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence2bertdataset(sentences):\n",
        "    ret_sentences = []\n",
        "    for sentence in sentences:\n",
        "        ret_sentences.append([sentence, 1])\n",
        "    return ret_sentences\n",
        "sentences = sentence2bertdataset(sentences)"
      ],
      "metadata": {
        "id": "-hXJGfCkqQE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[0]"
      ],
      "metadata": {
        "id": "8jBLm3DqqfA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bertdataset = BERTDataset(sentences, 0, 1, tok, max_len, True, False)"
      ],
      "metadata": {
        "id": "GIUIaY04pvEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bertdataset[0]"
      ],
      "metadata": {
        "id": "PrkF4dreqFGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bertToTorch(_data, device):\n",
        "    token_ids, valid_length, segment_ids, label = _data\n",
        "    token_ids = torch.tensor([token_ids])\n",
        "    segment_ids = torch.tensor([segment_ids])\n",
        "    token_ids = token_ids.long().to(device)\n",
        "    segment_ids = segment_ids.long().to(device)\n",
        "    valid_length = torch.IntTensor([valid_length.item()])\n",
        "    return token_ids, valid_length, segment_ids\n",
        "bertToTorch(bertdataset[0],device)"
      ],
      "metadata": {
        "id": "F7haJ2rbWnYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def labeling(_bertdataset, _model, score_func):\n",
        "    predicted_labels = []\n",
        "    for bs in _bertdataset:\n",
        "        token_ids, valid_length, segment_ids = bertToTorch(bs, device)\n",
        "        predicted = _model(token_ids, valid_length, segment_ids)\n",
        "        predicted_value = score_func(predicted)\n",
        "        predicted_labels.append(predicted_value)\n",
        "    \n",
        "    predicted_labels = np.array(predicted_labels)\n",
        "    return predicted_labels"
      ],
      "metadata": {
        "id": "GcqMpnjCWrHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scoring_func(_predicted):\n",
        "    predicted = _predicted.cpu().detach().numpy()\n",
        "    predicted_value = np.argmax(predicted)\n",
        "    return predicted_value\n"
      ],
      "metadata": {
        "id": "-7cjW4JUbsLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_labels = labeling(bertdataset, sentiment_model, scoring_func)\n",
        "sentiment_labels[:5]"
      ],
      "metadata": {
        "id": "XTmvsIdScHLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subjective_labels = labeling(bertdataset, subjective_model, scoring_func)\n",
        "subjective_labels[:5]"
      ],
      "metadata": {
        "id": "Iofq7soFcT2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "after_labeling_data_file_path = '/content/drive/MyDrive/dataset/labeled_미니어처.txt'\n",
        "sentences = df['sentence'].values\n",
        "with open(after_labeling_data_file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for sentence, sentiment, subjective in zip(sentences, sentiment_labels, subjective_labels):\n",
        "        f.write(f\"{sentence}\\t{sentiment}\\t{subjective}\\n\")"
      ],
      "metadata": {
        "id": "vomuLs8VdUZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "G1Hz0CRNexPD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}