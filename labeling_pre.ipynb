{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ratings_test.txt', <http.client.HTTPMessage at 0x1c7b52e58b0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\",filename=\"ratings_train.txt\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\",filename=\"ratings_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_table(\"./data/ratings_train.txt\")\n",
    "test_data = pd.read_table(\"./data/ratings_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113086</th>\n",
       "      <td>8828917</td>\n",
       "      <td>원작은 예술이었으나 이것은 그냥 킬링타임용 그이상도 그이하도 아님. 왜 굳이 리메이...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11552</th>\n",
       "      <td>5951295</td>\n",
       "      <td>유쾌하고 즐거우면서 아름다운 영화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12819</th>\n",
       "      <td>9895115</td>\n",
       "      <td>다양한 생각을 자연스럽게 인정하는 일본 그래서 문학이 발전하고 기발한 애니매이션도 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13871</th>\n",
       "      <td>10216097</td>\n",
       "      <td>오랜만에 다시 보았다....새롭기도하고 반갑기도했다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55540</th>\n",
       "      <td>9218022</td>\n",
       "      <td>너무재밋게보고있어요부모님이랑같이보는데 빵빵터지고 눈물샘도자극하네요..너무좋은프로그램...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                           document  label\n",
       "113086   8828917  원작은 예술이었으나 이것은 그냥 킬링타임용 그이상도 그이하도 아님. 왜 굳이 리메이...      0\n",
       "11552    5951295                                 유쾌하고 즐거우면서 아름다운 영화      1\n",
       "12819    9895115  다양한 생각을 자연스럽게 인정하는 일본 그래서 문학이 발전하고 기발한 애니매이션도 ...      1\n",
       "13871   10216097                       오랜만에 다시 보았다....새롭기도하고 반갑기도했다      1\n",
       "55540    9218022  너무재밋게보고있어요부모님이랑같이보는데 빵빵터지고 눈물샘도자극하네요..너무좋은프로그램...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop_duplicates(subset=['document'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>6222902</td>\n",
       "      <td>인간이 문제지.. 소는 뭔죄인가..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>8549745</td>\n",
       "      <td>평점이 너무 낮아서...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>9311800</td>\n",
       "      <td>이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>2376369</td>\n",
       "      <td>청춘 영화의 최고봉.방황과 우울했던 날들의 자화상</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>9619869</td>\n",
       "      <td>한국 영화 최초로 수간하는 내용이 담긴 영화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146182 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                           document  label\n",
       "0        9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1        3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2       10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3        9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4        6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
       "...          ...                                                ...    ...\n",
       "149995   6222902                                인간이 문제지.. 소는 뭔죄인가..      0\n",
       "149996   8549745                                      평점이 너무 낮아서...      1\n",
       "149997   9311800                    이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n",
       "149998   2376369                        청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n",
       "149999   9619869                           한국 영화 최초로 수간하는 내용이 담긴 영화      0\n",
       "\n",
       "[146182 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sechang\\AppData\\Local\\Temp/ipykernel_8904/2298155351.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
      "C:\\Users\\sechang\\AppData\\Local\\Temp/ipykernel_8904/2298155351.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"^ +\",\"\")\n"
     ]
    }
   ],
   "source": [
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_data['document'] = train_data['document'].str.replace(\"^ +\",\"\")\n",
    "train_data['document'].replace(\"\",np.nan, inplace=True)\n",
    "train_data = train_data.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sechang\\AppData\\Local\\Temp/ipykernel_8904/2047020776.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
      "C:\\Users\\sechang\\AppData\\Local\\Temp/ipykernel_8904/2047020776.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace(\"^ +\",\"\")\n"
     ]
    }
   ],
   "source": [
    "test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "test_data['document'] = test_data['document'].str.replace(\"^ +\",\"\")\n",
    "test_data['document'].replace(\"\",np.nan, inplace=True)\n",
    "test_data = test_data.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145393/145393 [14:31<00:00, 166.75it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "okt = Okt()\n",
    "for sentence in tqdm(train_data['document']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True)\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords]\n",
    "    X_train.append(stopwords_removed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['아', '더빙', '진짜', '짜증나다', '목소리'],\n",
       " ['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기', '조차', '가볍다', '않다'],\n",
       " ['너', '무재', '밓었', '다그', '래서', '보다', '추천', '다']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49575/49575 [02:33<00:00, 322.01it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "for sentence in tqdm(test_data['document']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True)\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords]\n",
    "    X_test.append(stopwords_removed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'영화': 1,\n",
       " '보다': 2,\n",
       " '을': 3,\n",
       " '없다': 4,\n",
       " '이다': 5,\n",
       " '있다': 6,\n",
       " '좋다': 7,\n",
       " '너무': 8,\n",
       " '다': 9,\n",
       " '정말': 10,\n",
       " '되다': 11,\n",
       " '재밌다': 12,\n",
       " '적': 13,\n",
       " '만': 14,\n",
       " '같다': 15,\n",
       " '진짜': 16,\n",
       " '로': 17,\n",
       " '아니다': 18,\n",
       " '않다': 19,\n",
       " '점': 20,\n",
       " '에서': 21,\n",
       " '만들다': 22,\n",
       " '나오다': 23,\n",
       " '연기': 24,\n",
       " '것': 25,\n",
       " '평점': 26,\n",
       " '내': 27,\n",
       " '최고': 28,\n",
       " '그': 29,\n",
       " '나': 30,\n",
       " '안': 31,\n",
       " '인': 32,\n",
       " '스토리': 33,\n",
       " '생각': 34,\n",
       " '못': 35,\n",
       " '왜': 36,\n",
       " '드라마': 37,\n",
       " '게': 38,\n",
       " '감동': 39,\n",
       " '사람': 40,\n",
       " '보고': 41,\n",
       " '이렇다': 42,\n",
       " '말': 43,\n",
       " '고': 44,\n",
       " '아깝다': 45,\n",
       " '더': 46,\n",
       " '배우': 47,\n",
       " '때': 48,\n",
       " 'ㅋㅋ': 49,\n",
       " '아': 50,\n",
       " '감독': 51,\n",
       " '거': 52,\n",
       " '그냥': 53,\n",
       " '재미있다': 54,\n",
       " '요': 55,\n",
       " '재미': 56,\n",
       " '시간': 57,\n",
       " '내용': 58,\n",
       " '뭐': 59,\n",
       " '까지': 60,\n",
       " '중': 61,\n",
       " '주다': 62,\n",
       " '자다': 63,\n",
       " '하고': 64,\n",
       " '지루하다': 65,\n",
       " '재미없다': 66,\n",
       " '쓰레기': 67,\n",
       " '수': 68,\n",
       " '네': 69,\n",
       " '모르다': 70,\n",
       " '가다': 71,\n",
       " '들다': 72,\n",
       " '그렇다': 73,\n",
       " '싶다': 74,\n",
       " '지': 75,\n",
       " '작품': 76,\n",
       " '사랑': 77,\n",
       " '알다': 78,\n",
       " '하나': 79,\n",
       " '다시': 80,\n",
       " '마지막': 81,\n",
       " '볼': 82,\n",
       " '이건': 83,\n",
       " '정도': 84,\n",
       " '저': 85,\n",
       " '완전': 86,\n",
       " '오다': 87,\n",
       " 'ㅋ': 88,\n",
       " 'ㅠㅠ': 89,\n",
       " '많다': 90,\n",
       " '처음': 91,\n",
       " 'ㅋㅋㅋ': 92,\n",
       " '장면': 93,\n",
       " '액션': 94,\n",
       " '주인공': 95,\n",
       " '이렇게': 96,\n",
       " '안되다': 97,\n",
       " '걸': 98,\n",
       " '차다': 99,\n",
       " '나다': 100,\n",
       " '개': 101,\n",
       " '하': 102,\n",
       " '최악': 103,\n",
       " '돈': 104,\n",
       " '이야기': 105,\n",
       " '지금': 106,\n",
       " '넘다': 107,\n",
       " '느낌': 108,\n",
       " '임': 109,\n",
       " '연출': 110,\n",
       " 'ㅡㅡ': 111,\n",
       " '라': 112,\n",
       " '인데': 113,\n",
       " '듯': 114,\n",
       " '끝': 115,\n",
       " '명작': 116,\n",
       " '좋아하다': 117,\n",
       " '그리고': 118,\n",
       " '년': 119,\n",
       " '별로': 120,\n",
       " '역시': 121,\n",
       " '받다': 122,\n",
       " '기': 123,\n",
       " '많이': 124,\n",
       " '남다': 125,\n",
       " '별': 126,\n",
       " '이해': 127,\n",
       " '난': 128,\n",
       " '면': 129,\n",
       " '이런': 130,\n",
       " '이영화': 131,\n",
       " '분': 132,\n",
       " '괜찮다': 133,\n",
       " '라고': 134,\n",
       " '느끼다': 135,\n",
       " '또': 136,\n",
       " '버리다': 137,\n",
       " '이나': 138,\n",
       " '때문': 139,\n",
       " '성': 140,\n",
       " '여자': 141,\n",
       " '서': 142,\n",
       " '부터': 143,\n",
       " '먹다': 144,\n",
       " '일': 145,\n",
       " '아름답다': 146,\n",
       " '해주다': 147,\n",
       " '꼭': 148,\n",
       " '보기': 149,\n",
       " '엔': 150,\n",
       " '이고': 151,\n",
       " '두': 152,\n",
       " '무슨': 153,\n",
       " '여': 154,\n",
       " '에게': 155,\n",
       " '기억': 156,\n",
       " '결말': 157,\n",
       " '편': 158,\n",
       " '대': 159,\n",
       " 'ㅎㅎ': 160,\n",
       " '랑': 161,\n",
       " '야': 162,\n",
       " '짱': 163,\n",
       " '아쉽다': 164,\n",
       " '인생': 165,\n",
       " '마음': 166,\n",
       " '영': 167,\n",
       " '소재': 168,\n",
       " '뻔하다': 169,\n",
       " '끄다': 170,\n",
       " '애': 171,\n",
       " '전': 172,\n",
       " '보여주다': 173,\n",
       " '님': 174,\n",
       " '어떻다': 175,\n",
       " '없이': 176,\n",
       " '수준': 177,\n",
       " '어리다': 178,\n",
       " '현실': 179,\n",
       " '무섭다': 180,\n",
       " '맞다': 181,\n",
       " '한번': 182,\n",
       " '속': 183,\n",
       " '씨': 184,\n",
       " '가장': 185,\n",
       " '재다': 186,\n",
       " '급': 187,\n",
       " '본': 188,\n",
       " '웃기다': 189,\n",
       " '반전': 190,\n",
       " '매력': 191,\n",
       " '되어다': 192,\n",
       " '전개': 193,\n",
       " '제': 194,\n",
       " '라는': 195,\n",
       " '한국': 196,\n",
       " '남자': 197,\n",
       " '끝나다': 198,\n",
       " '가슴': 199,\n",
       " '뿐': 200,\n",
       " '낮다': 201,\n",
       " '말다': 202,\n",
       " '아이': 203,\n",
       " '죽다': 204,\n",
       " '슬프다': 205,\n",
       " '높다': 206,\n",
       " '유치하다': 207,\n",
       " '음악': 208,\n",
       " '알': 209,\n",
       " '니': 210,\n",
       " '다른': 211,\n",
       " '멋지다': 212,\n",
       " '원작': 213,\n",
       " '줄': 214,\n",
       " '늘다': 215,\n",
       " '인간': 216,\n",
       " '화': 217,\n",
       " '솔직하다': 218,\n",
       " '크다': 219,\n",
       " '냐': 220,\n",
       " '우리': 221,\n",
       " '추천': 222,\n",
       " '눈물': 223,\n",
       " '쓰다': 224,\n",
       " '살다': 225,\n",
       " '인지': 226,\n",
       " '모든': 227,\n",
       " '지만': 228,\n",
       " '내다': 229,\n",
       " '함': 230,\n",
       " '자체': 231,\n",
       " '번': 232,\n",
       " '야하다': 233,\n",
       " '허다': 234,\n",
       " '눈': 235,\n",
       " '찍다': 236,\n",
       " '하지만': 237,\n",
       " '인가': 238,\n",
       " '캐릭터': 239,\n",
       " '보이다': 240,\n",
       " '코미디': 241,\n",
       " '처럼': 242,\n",
       " 'ㅋㅋㅋㅋ': 243,\n",
       " '대한': 244,\n",
       " '움': 245,\n",
       " '모두': 246,\n",
       " '이상': 247,\n",
       " '뭔가': 248,\n",
       " '대박': 249,\n",
       " 'ㅠ': 250,\n",
       " '돼다': 251,\n",
       " '이네': 252,\n",
       " '전혀': 253,\n",
       " '이쁘다': 254,\n",
       " '연기력': 255,\n",
       " '건지다': 256,\n",
       " '여운': 257,\n",
       " '미치다': 258,\n",
       " '그래도': 259,\n",
       " '짜증나다': 260,\n",
       " '개봉': 261,\n",
       " '공감': 262,\n",
       " '일본': 263,\n",
       " '기대': 264,\n",
       " '기대하다': 265,\n",
       " '시리즈': 266,\n",
       " '근데': 267,\n",
       " '중간': 268,\n",
       " '지다': 269,\n",
       " '표현': 270,\n",
       " '영상': 271,\n",
       " '부분': 272,\n",
       " '아주': 273,\n",
       " '모습': 274,\n",
       " '에는': 275,\n",
       " '작': 276,\n",
       " '제목': 277,\n",
       " '계속': 278,\n",
       " '이랑': 279,\n",
       " '치다': 280,\n",
       " '귀엽다': 281,\n",
       " '이라': 282,\n",
       " '시키다': 283,\n",
       " 'ㅜㅜ': 284,\n",
       " '가족': 285,\n",
       " '내내': 286,\n",
       " '뭔': 287,\n",
       " '보지': 288,\n",
       " '믿다': 289,\n",
       " '진심': 290,\n",
       " '실망': 291,\n",
       " '몰입': 292,\n",
       " '밖에': 293,\n",
       " '후': 294,\n",
       " '짜다': 295,\n",
       " '기분': 296,\n",
       " '대단하다': 297,\n",
       " '연': 298,\n",
       " '작가': 299,\n",
       " '떨어지다': 300,\n",
       " '건': 301,\n",
       " '잔잔하다': 302,\n",
       " 'ㅎ': 303,\n",
       " '이제': 304,\n",
       " '위': 305,\n",
       " '웃다': 306,\n",
       " '요즘': 307,\n",
       " '공포': 308,\n",
       " '빠지다': 309,\n",
       " '스릴러': 310,\n",
       " '이라는': 311,\n",
       " '시': 312,\n",
       " '감': 313,\n",
       " '긴장감': 314,\n",
       " '개인': 315,\n",
       " '용': 316,\n",
       " '잼': 317,\n",
       " '조금': 318,\n",
       " '애니': 319,\n",
       " '대사': 320,\n",
       " '이유': 321,\n",
       " '알바': 322,\n",
       " '특히': 323,\n",
       " '제대로': 324,\n",
       " '삶': 325,\n",
       " '울다': 326,\n",
       " '극장': 327,\n",
       " '점도': 328,\n",
       " '노래': 329,\n",
       " '한테': 330,\n",
       " '딱': 331,\n",
       " '욕': 332,\n",
       " '굿': 333,\n",
       " '점수': 334,\n",
       " '잇다': 335,\n",
       " '시작': 336,\n",
       " '막장': 337,\n",
       " '이란': 338,\n",
       " '나름': 339,\n",
       " '오랜': 340,\n",
       " '이상하다': 341,\n",
       " '극': 342,\n",
       " '이지': 343,\n",
       " '예쁘다': 344,\n",
       " '깊다': 345,\n",
       " '에도': 346,\n",
       " '노잼': 347,\n",
       " '제일': 348,\n",
       " '차라리': 349,\n",
       " '놈': 350,\n",
       " '느껴지다': 351,\n",
       " '친구': 352,\n",
       " '해보다': 353,\n",
       " '영화로': 354,\n",
       " '당시': 355,\n",
       " '같이': 356,\n",
       " '어설프다': 357,\n",
       " '의미': 358,\n",
       " '절대': 359,\n",
       " '빼다': 360,\n",
       " '식': 361,\n",
       " '력': 362,\n",
       " '위해': 363,\n",
       " '류': 364,\n",
       " '세상': 365,\n",
       " '따뜻하다': 366,\n",
       " '찾다': 367,\n",
       " '몇': 368,\n",
       " '아직도': 369,\n",
       " '훌륭하다': 370,\n",
       " '이라고': 371,\n",
       " '년대': 372,\n",
       " '공포영화': 373,\n",
       " '명': 374,\n",
       " '미국': 375,\n",
       " '웃음': 376,\n",
       " '도대체': 377,\n",
       " '생각나다': 378,\n",
       " '설정': 379,\n",
       " '아무': 380,\n",
       " '앞': 381,\n",
       " '무엇': 382,\n",
       " '마다': 383,\n",
       " '그리다': 384,\n",
       " '오': 385,\n",
       " '너': 386,\n",
       " '죽이다': 387,\n",
       " '어': 388,\n",
       " '초반': 389,\n",
       " '써다': 390,\n",
       " '다르다': 391,\n",
       " '데': 392,\n",
       " '물': 393,\n",
       " '뭘': 394,\n",
       " '우리나라': 395,\n",
       " '출연': 396,\n",
       " '수작': 397,\n",
       " '따다': 398,\n",
       " '힘들다': 399,\n",
       " '답답하다': 400,\n",
       " '사실': 401,\n",
       " '싫다': 402,\n",
       " '엄청': 403,\n",
       " '추억': 404,\n",
       " '한국영': 405,\n",
       " '가지': 406,\n",
       " '반': 407,\n",
       " '남': 408,\n",
       " '멋있다': 409,\n",
       " '놓다': 410,\n",
       " '시나리오': 411,\n",
       " '신선하다': 412,\n",
       " '아프다': 413,\n",
       " '관객': 414,\n",
       " '분위기': 415,\n",
       " '이야': 416,\n",
       " '필요없다': 417,\n",
       " '대다': 418,\n",
       " '팬': 419,\n",
       " '기다': 420,\n",
       " '장난': 421,\n",
       " '시대': 422,\n",
       " '해': 423,\n",
       " '지루함': 424,\n",
       " '어이없다': 425,\n",
       " '잊다': 426,\n",
       " '세': 427,\n",
       " '나쁘다': 428,\n",
       " '살': 429,\n",
       " '자신': 430,\n",
       " '소리': 431,\n",
       " '이딴': 432,\n",
       " '감정': 433,\n",
       " '졸작': 434,\n",
       " '엔딩': 435,\n",
       " '이지만': 436,\n",
       " '영화관': 437,\n",
       " '준': 438,\n",
       " '안타깝다': 439,\n",
       " '오늘': 440,\n",
       " '엄마': 441,\n",
       " '멀다': 442,\n",
       " '구': 443,\n",
       " '결국': 444,\n",
       " '접': 445,\n",
       " '제발': 446,\n",
       " '정신': 447,\n",
       " '봄': 448,\n",
       " '주': 449,\n",
       " '인상': 450,\n",
       " '부족하다': 451,\n",
       " '스럽다': 452,\n",
       " '배우다': 453,\n",
       " '더빙': 454,\n",
       " '원': 455,\n",
       " '더럽다': 456,\n",
       " '포스터': 457,\n",
       " '캐스팅': 458,\n",
       " '라면': 459,\n",
       " '최고다': 460,\n",
       " '평가': 461,\n",
       " '코믹': 462,\n",
       " '문제': 463,\n",
       " '니까': 464,\n",
       " '얼마나': 465,\n",
       " '아무리': 466,\n",
       " '엉': 467,\n",
       " '애니메이션': 468,\n",
       " '함께': 469,\n",
       " '그저': 470,\n",
       " '어색하다': 471,\n",
       " '몰입도': 472,\n",
       " '서다': 473,\n",
       " '신': 474,\n",
       " '낫다': 475,\n",
       " '티비': 476,\n",
       " '기도': 477,\n",
       " '든': 478,\n",
       " '배경': 479,\n",
       " '비다': 480,\n",
       " '첨': 481,\n",
       " '살리다': 482,\n",
       " '두다': 483,\n",
       " '대해': 484,\n",
       " '유쾌하다': 485,\n",
       " '음': 486,\n",
       " '쓸다': 487,\n",
       " '뒤': 488,\n",
       " '망하다': 489,\n",
       " '맘': 490,\n",
       " '킬링타임': 491,\n",
       " '나가다': 492,\n",
       " '스릴': 493,\n",
       " '충격': 494,\n",
       " '완벽하다': 495,\n",
       " '전쟁': 496,\n",
       " '만화': 497,\n",
       " '얘기': 498,\n",
       " '진부하다': 499,\n",
       " '등': 500,\n",
       " '존나': 501,\n",
       " '적다': 502,\n",
       " '책': 503,\n",
       " '건가': 504,\n",
       " '개연': 505,\n",
       " '예술': 506,\n",
       " '그렇게': 507,\n",
       " '간': 508,\n",
       " '머': 509,\n",
       " '머리': 510,\n",
       " '갈수록': 511,\n",
       " '매우': 512,\n",
       " '질': 513,\n",
       " '즐겁다': 514,\n",
       " '놀라다': 515,\n",
       " '조': 516,\n",
       " '얼굴': 517,\n",
       " '보단': 518,\n",
       " '웃기': 519,\n",
       " '후회': 520,\n",
       " '이름': 521,\n",
       " '읽다': 522,\n",
       " '영화인': 523,\n",
       " '너무나': 524,\n",
       " '옛날': 525,\n",
       " '구성': 526,\n",
       " '어디': 527,\n",
       " '어울리다': 528,\n",
       " '행복하다': 529,\n",
       " '집중': 530,\n",
       " '이후': 531,\n",
       " '들이다': 532,\n",
       " '울': 533,\n",
       " '총': 534,\n",
       " '꽤': 535,\n",
       " '장르': 536,\n",
       " '집': 537,\n",
       " '새롭다': 538,\n",
       " '주연': 539,\n",
       " '날': 540,\n",
       " '다큐': 541,\n",
       " '시즌': 542,\n",
       " '상황': 543,\n",
       " '누구': 544,\n",
       " '그래서': 545,\n",
       " '이리': 546,\n",
       " '상': 547,\n",
       " '억지': 548,\n",
       " '언제': 549,\n",
       " '짜증': 550,\n",
       " '씬': 551,\n",
       " '생기다': 552,\n",
       " '예전': 553,\n",
       " '글': 554,\n",
       " '충분하다': 555,\n",
       " '아직': 556,\n",
       " '후반': 557,\n",
       " '비': 558,\n",
       " '다운': 559,\n",
       " '역사': 560,\n",
       " '강추': 561,\n",
       " '어느': 562,\n",
       " '걸작': 563,\n",
       " '궁금하다': 564,\n",
       " '불쌍하다': 565,\n",
       " '여기': 566,\n",
       " '누가': 567,\n",
       " '밉다': 568,\n",
       " '진': 569,\n",
       " '약간': 570,\n",
       " '훨씬': 571,\n",
       " '자기': 572,\n",
       " '소름': 573,\n",
       " '그것': 574,\n",
       " '인물': 575,\n",
       " '실화': 576,\n",
       " '발연기': 577,\n",
       " '그나마': 578,\n",
       " '해도': 579,\n",
       " '그대로': 580,\n",
       " '방송': 581,\n",
       " '심하다': 582,\n",
       " '분들': 583,\n",
       " '시절': 584,\n",
       " '만점': 585,\n",
       " '잔인하다': 586,\n",
       " '회': 587,\n",
       " '비디오': 588,\n",
       " '대체': 589,\n",
       " '순수하다': 590,\n",
       " '비슷하다': 591,\n",
       " '그런': 592,\n",
       " '드리다': 593,\n",
       " '소설': 594,\n",
       " '한마디': 595,\n",
       " '사회': 596,\n",
       " '로맨스': 597,\n",
       " '아들': 598,\n",
       " '어렵다': 599,\n",
       " '부': 600,\n",
       " '비교': 601,\n",
       " '초딩': 602,\n",
       " '필요하다': 603,\n",
       " '감성': 604,\n",
       " '판': 605,\n",
       " '네이버': 606,\n",
       " '쉬다': 607,\n",
       " '따르다': 608,\n",
       " '보': 609,\n",
       " '휴': 610,\n",
       " '남기다': 611,\n",
       " '다음': 612,\n",
       " '만나다': 613,\n",
       " '여주': 614,\n",
       " '여배우': 615,\n",
       " '전체': 616,\n",
       " '간만': 617,\n",
       " '타다': 618,\n",
       " '죠': 619,\n",
       " '떠나다': 620,\n",
       " '상당하다': 621,\n",
       " '라도': 622,\n",
       " '편이': 623,\n",
       " '장': 624,\n",
       " '나이': 625,\n",
       " '사랑스럽다': 626,\n",
       " '만큼': 627,\n",
       " '이라도': 628,\n",
       " '당하다': 629,\n",
       " '꿈': 630,\n",
       " '나라': 631,\n",
       " '코': 632,\n",
       " '성룡': 633,\n",
       " '재': 634,\n",
       " '굉장하다': 635,\n",
       " '동안': 636,\n",
       " '이르다': 637,\n",
       " '혼자': 638,\n",
       " '열': 639,\n",
       " '터지다': 640,\n",
       " '순간': 641,\n",
       " '돌리다': 642,\n",
       " '교훈': 643,\n",
       " '쯤': 644,\n",
       " '삼류': 645,\n",
       " '보다는': 646,\n",
       " '재밋': 647,\n",
       " '감사하다': 648,\n",
       " '빨리': 649,\n",
       " '존재': 650,\n",
       " '그만': 651,\n",
       " '힘': 652,\n",
       " 'ㅉㅉ': 653,\n",
       " '바로': 654,\n",
       " '풀다': 655,\n",
       " '주제': 656,\n",
       " '바라다': 657,\n",
       " '진정하다': 658,\n",
       " '목소리': 659,\n",
       " '에요': 660,\n",
       " '년도': 661,\n",
       " '억': 662,\n",
       " '잡다': 663,\n",
       " '죽': 664,\n",
       " '망치다': 665,\n",
       " '화려하다': 666,\n",
       " '당신': 667,\n",
       " '돋다': 668,\n",
       " '지나다': 669,\n",
       " '거의': 670,\n",
       " '안보': 671,\n",
       " '낭비': 672,\n",
       " '몇번': 673,\n",
       " '질질': 674,\n",
       " '가볍다': 675,\n",
       " '년전': 676,\n",
       " '라니': 677,\n",
       " '독특하다': 678,\n",
       " '말고': 679,\n",
       " '엄청나다': 680,\n",
       " '줄거리': 681,\n",
       " '맞추다': 682,\n",
       " '성하다': 683,\n",
       " '뜨다': 684,\n",
       " 'ㅜ': 685,\n",
       " '의도': 686,\n",
       " '에선': 687,\n",
       " '딸': 688,\n",
       " '아버지': 689,\n",
       " '좀비': 690,\n",
       " '판타지': 691,\n",
       " '이번': 692,\n",
       " '담다': 693,\n",
       " '갑자기': 694,\n",
       " '그러나': 695,\n",
       " '어른': 696,\n",
       " '넣다': 697,\n",
       " '피': 698,\n",
       " '전부': 699,\n",
       " '점주': 700,\n",
       " '당': 701,\n",
       " '상영': 702,\n",
       " '모': 703,\n",
       " '시청률': 704,\n",
       " '흥미롭다': 705,\n",
       " '실제': 706,\n",
       " '소': 707,\n",
       " 'ㅎㅎㅎ': 708,\n",
       " '넘치다': 709,\n",
       " 'ㅡ': 710,\n",
       " '힘드다': 711,\n",
       " '평론가': 712,\n",
       " '곳': 713,\n",
       " '으로도': 714,\n",
       " '맛': 715,\n",
       " '점점': 716,\n",
       " '필요': 717,\n",
       " '만하': 718,\n",
       " '땜': 719,\n",
       " '단': 720,\n",
       " '기다리다': 721,\n",
       " '막': 722,\n",
       " '한편': 723,\n",
       " '그녀': 724,\n",
       " '히': 725,\n",
       " '제작': 726,\n",
       " '화면': 727,\n",
       " '사': 728,\n",
       " '바': 729,\n",
       " '대로': 730,\n",
       " '극장판': 731,\n",
       " '만들어지다': 732,\n",
       " '초': 733,\n",
       " '이기다': 734,\n",
       " '답': 735,\n",
       " '중국': 736,\n",
       " '형': 737,\n",
       " '온': 738,\n",
       " '각본': 739,\n",
       " '간다': 740,\n",
       " '에서도': 741,\n",
       " '볼때': 742,\n",
       " '억지스럽다': 743,\n",
       " '래': 744,\n",
       " '밑': 745,\n",
       " '굳다': 746,\n",
       " '평': 747,\n",
       " '달다': 748,\n",
       " '바꾸다': 749,\n",
       " '관람': 750,\n",
       " '란': 751,\n",
       " '오글거리다': 752,\n",
       " '저런': 753,\n",
       " '이하': 754,\n",
       " '스타일': 755,\n",
       " '세계': 756,\n",
       " '선택': 757,\n",
       " '선': 758,\n",
       " '성우': 759,\n",
       " '요소': 760,\n",
       " '터': 761,\n",
       " '둘': 762,\n",
       " '복수': 763,\n",
       " '항상': 764,\n",
       " '일단': 765,\n",
       " '똥': 766,\n",
       " '가치': 767,\n",
       " '햇': 768,\n",
       " '어디서': 769,\n",
       " '에서는': 770,\n",
       " '뻔': 771,\n",
       " '첫': 772,\n",
       " '갖다': 773,\n",
       " '올리다': 774,\n",
       " '흥행': 775,\n",
       " '부르다': 776,\n",
       " '보내다': 777,\n",
       " '참고': 778,\n",
       " '그때': 779,\n",
       " '가보다': 780,\n",
       " '드': 781,\n",
       " '너무하다': 782,\n",
       " '여러': 783,\n",
       " '걸리다': 784,\n",
       " '더욱': 785,\n",
       " '치고': 786,\n",
       " '확실하다': 787,\n",
       " '라서': 788,\n",
       " '들어가다': 789,\n",
       " '또한': 790,\n",
       " '아빠': 791,\n",
       " '평범하다': 792,\n",
       " '씩': 793,\n",
       " '물론': 794,\n",
       " '수가': 795,\n",
       " '역대': 796,\n",
       " '발': 797,\n",
       " '거기': 798,\n",
       " '불편하다': 799,\n",
       " 'ㅋㅋㅋㅋㅋ': 800,\n",
       " '인거': 801,\n",
       " '완성': 802,\n",
       " '편집': 803,\n",
       " '단순하다': 804,\n",
       " '이냐': 805,\n",
       " '잃다': 806,\n",
       " '상미': 807,\n",
       " '전형': 808,\n",
       " '멜로': 809,\n",
       " '듣다': 810,\n",
       " '끼다': 811,\n",
       " '흐르다': 812,\n",
       " '허무하다': 813,\n",
       " '짧다': 814,\n",
       " '새끼': 815,\n",
       " '짓': 816,\n",
       " '어이': 817,\n",
       " 'ㅠㅠㅠ': 818,\n",
       " '때리다': 819,\n",
       " '화이팅': 820,\n",
       " '역': 821,\n",
       " '걸다': 822,\n",
       " '이에요': 823,\n",
       " '귀': 824,\n",
       " '술': 825,\n",
       " '탄탄하다': 826,\n",
       " '군': 827,\n",
       " '진행': 828,\n",
       " '가지다': 829,\n",
       " '불륜': 830,\n",
       " '개그': 831,\n",
       " '에겐': 832,\n",
       " '돋보이다': 833,\n",
       " '엉망': 834,\n",
       " '거지': 835,\n",
       " '예상': 836,\n",
       " '병맛': 837,\n",
       " '잠': 838,\n",
       " '사건': 839,\n",
       " '즐기다': 840,\n",
       " '중반': 841,\n",
       " '지겹다': 842,\n",
       " '미화': 843,\n",
       " '소중하다': 844,\n",
       " '그게': 845,\n",
       " '똑같다': 846,\n",
       " '어쩔': 847,\n",
       " '설명': 848,\n",
       " '과거': 849,\n",
       " '메다': 850,\n",
       " '찾아보다': 851,\n",
       " '적당하다': 852,\n",
       " '프랑스': 853,\n",
       " '중요하다': 854,\n",
       " '화보': 855,\n",
       " '키': 856,\n",
       " '불다': 857,\n",
       " '훈훈하다': 858,\n",
       " '꿀잼': 859,\n",
       " '도저히': 860,\n",
       " '손': 861,\n",
       " '노력': 862,\n",
       " '흥미진진': 863,\n",
       " '댓글': 864,\n",
       " '그래픽': 865,\n",
       " '흥미': 866,\n",
       " '닿다': 867,\n",
       " '갈다': 868,\n",
       " '싸우다': 869,\n",
       " '거리': 870,\n",
       " '여서': 871,\n",
       " '죽음': 872,\n",
       " '취향': 873,\n",
       " '티': 874,\n",
       " '무조건': 875,\n",
       " '원래': 876,\n",
       " '몸': 877,\n",
       " '식상하다': 878,\n",
       " '척': 879,\n",
       " '리': 880,\n",
       " '화가': 881,\n",
       " '새': 882,\n",
       " '뛰어나다': 883,\n",
       " '비추다': 884,\n",
       " '일이': 885,\n",
       " '마르다': 886,\n",
       " '현': 887,\n",
       " '자극': 888,\n",
       " '배': 889,\n",
       " '감상': 890,\n",
       " '며': 891,\n",
       " '역겹다': 892,\n",
       " '한심하다': 893,\n",
       " '만으로도': 894,\n",
       " '만이': 895,\n",
       " '예': 896,\n",
       " '학교': 897,\n",
       " '길다': 898,\n",
       " '자꾸': 899,\n",
       " '괜히': 900,\n",
       " '무': 901,\n",
       " '액션영화': 902,\n",
       " '암': 903,\n",
       " '관': 904,\n",
       " '뭐라다': 905,\n",
       " '예고편': 906,\n",
       " '오히려': 907,\n",
       " '바보': 908,\n",
       " '결혼': 909,\n",
       " '다가': 910,\n",
       " '심리': 911,\n",
       " '다루다': 912,\n",
       " '이라니': 913,\n",
       " '게임': 914,\n",
       " '아저씨': 915,\n",
       " '속편': 916,\n",
       " '용도': 917,\n",
       " '연기자': 918,\n",
       " '보이': 919,\n",
       " '잘만': 920,\n",
       " '마무리': 921,\n",
       " '나서다': 922,\n",
       " '올': 923,\n",
       " '강하다': 924,\n",
       " '관계': 925,\n",
       " '양': 926,\n",
       " '나르다': 927,\n",
       " '왠만하다': 928,\n",
       " '천재': 929,\n",
       " '법': 930,\n",
       " '미안하다': 931,\n",
       " '맨': 932,\n",
       " '흠': 933,\n",
       " '헐다': 934,\n",
       " 'ㄷㄷ': 935,\n",
       " '억지로': 936,\n",
       " '표정': 937,\n",
       " '땐': 938,\n",
       " '참신하다': 939,\n",
       " '영환': 940,\n",
       " '귀신': 941,\n",
       " '최근': 942,\n",
       " '한다는': 943,\n",
       " '전설': 944,\n",
       " '순': 945,\n",
       " '기억나다': 946,\n",
       " '현재': 947,\n",
       " '상상': 948,\n",
       " '동': 949,\n",
       " '유치': 950,\n",
       " '젠': 951,\n",
       " '타임': 952,\n",
       " '촬영': 953,\n",
       " '오빠': 954,\n",
       " '대한민국': 955,\n",
       " '아쉬움': 956,\n",
       " '봣': 957,\n",
       " '오래': 958,\n",
       " '다니다': 959,\n",
       " '산': 960,\n",
       " '조차': 961,\n",
       " '빠져들다': 962,\n",
       " '우연히': 963,\n",
       " '엇': 964,\n",
       " '흘리다': 965,\n",
       " '짐': 966,\n",
       " '잊혀지다': 967,\n",
       " '전편': 968,\n",
       " '길': 969,\n",
       " '스타': 970,\n",
       " '묘사': 971,\n",
       " '대작': 972,\n",
       " '메세지': 973,\n",
       " '진지하다': 974,\n",
       " '만의': 975,\n",
       " '철학': 976,\n",
       " '겁나다': 977,\n",
       " '타': 978,\n",
       " '프로그램': 979,\n",
       " '마': 980,\n",
       " '동화': 981,\n",
       " '프로': 982,\n",
       " '돌아가다': 983,\n",
       " '그림': 984,\n",
       " '드럽다': 985,\n",
       " '작다': 986,\n",
       " '하하': 987,\n",
       " '지루': 988,\n",
       " '만에': 989,\n",
       " '여전하다': 990,\n",
       " '사라지다': 991,\n",
       " '예요': 992,\n",
       " '전달': 993,\n",
       " '서로': 994,\n",
       " '공': 995,\n",
       " '역할': 996,\n",
       " '실망하다': 997,\n",
       " '유머': 998,\n",
       " '등장': 999,\n",
       " '졸라': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3\n",
    "total_cnt = len(tokenizer.word_index)\n",
    "rare_cnt = 0\n",
    "total_freq = 0\n",
    "rare_freq = 0\n",
    "\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    if value < threshold:\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19416"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = total_cnt - rare_cnt + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[50, 454, 16, 260, 659],\n",
       " [933, 457, 41, 602, 1, 214, 1449, 24, 961, 675, 19],\n",
       " [386, 2444, 2315, 5671, 2, 222, 9]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_data['label'])\n",
    "y_test = np.array(test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145162\n",
      "145162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sechang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.delete(X_train, drop_train, axis=0)\n",
    "y_train = np.delete(y_train, drop_train, axis=0)\n",
    "print(len(X_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "    count = 0 \n",
    "    for sentence in nested_list:\n",
    "        if len(sentence) <= max_len:\n",
    "            count = count + 1\n",
    "    print(f\"전체 샘플 중 길이가 {max_len}이하인 샘플의 비율: {count/len(nested_list) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 30이하인 샘플의 비율: 94.31944999380003\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(30,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=30)\n",
    "X_test = pad_sequences(X_test , maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  50,\n",
       "       454,  16, 260, 659])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1815/1815 [==============================] - ETA: 0s - loss: 0.3906 - acc: 0.8217\n",
      "Epoch 00001: saving model to best_model.h5\n",
      "1815/1815 [==============================] - 318s 168ms/step - loss: 0.3906 - acc: 0.8217 - val_loss: 0.3533 - val_acc: 0.8448\n",
      "Epoch 2/15\n",
      "1815/1815 [==============================] - ETA: 0s - loss: 0.3284 - acc: 0.8572\n",
      "Epoch 00002: saving model to best_model.h5\n",
      "1815/1815 [==============================] - 262s 144ms/step - loss: 0.3284 - acc: 0.8572 - val_loss: 0.3329 - val_acc: 0.8572\n",
      "Epoch 3/15\n",
      "1815/1815 [==============================] - ETA: 0s - loss: 0.3028 - acc: 0.8719\n",
      "Epoch 00003: saving model to best_model.h5\n",
      "1815/1815 [==============================] - 218s 120ms/step - loss: 0.3028 - acc: 0.8719 - val_loss: 0.3347 - val_acc: 0.8535\n",
      "Epoch 4/15\n",
      "1815/1815 [==============================] - ETA: 0s - loss: 0.2835 - acc: 0.8821\n",
      "Epoch 00004: saving model to best_model.h5\n",
      "1815/1815 [==============================] - 156s 86ms/step - loss: 0.2835 - acc: 0.8821 - val_loss: 0.3304 - val_acc: 0.8592\n",
      "Epoch 5/15\n",
      "1815/1815 [==============================] - ETA: 0s - loss: 0.2669 - acc: 0.8913\n",
      "Epoch 00005: saving model to best_model.h5\n",
      "1815/1815 [==============================] - 158s 87ms/step - loss: 0.2669 - acc: 0.8913 - val_loss: 0.3290 - val_acc: 0.8592\n",
      "Epoch 6/15\n",
      "1815/1815 [==============================] - ETA: 0s - loss: 0.2516 - acc: 0.8988- ETA: 2s - loss: 0.2517 - acc: 0.898 - ETA: 2s - loss:\n",
      "Epoch 00006: saving model to best_model.h5\n",
      "1815/1815 [==============================] - 193s 106ms/step - loss: 0.2516 - acc: 0.8988 - val_loss: 0.3391 - val_acc: 0.8583\n",
      "Epoch 7/15\n",
      "1815/1815 [==============================] - ETA: 0s - loss: 0.2368 - acc: 0.9054- ETA: 4s - loss: 0.2 - ETA: 2s -\n",
      "Epoch 00007: saving model to best_model.h5\n",
      "1815/1815 [==============================] - 193s 106ms/step - loss: 0.2368 - acc: 0.9054 - val_loss: 0.3500 - val_acc: 0.8539\n",
      "Epoch 8/15\n",
      "1815/1815 [==============================] - ETA: 0s - loss: 0.2219 - acc: 0.9124\n",
      "Epoch 00008: saving model to best_model.h5\n",
      "1815/1815 [==============================] - 196s 108ms/step - loss: 0.2219 - acc: 0.9124 - val_loss: 0.3612 - val_acc: 0.8508\n",
      "Epoch 9/15\n",
      "1815/1815 [==============================] - ETA: 0s - loss: 0.2065 - acc: 0.9193\n",
      "Epoch 00009: saving model to best_model.h5\n",
      "1815/1815 [==============================] - 156s 86ms/step - loss: 0.2065 - acc: 0.9193 - val_loss: 0.3703 - val_acc: 0.8475\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_units = 128 \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_bset_only=True)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1550/1550 [==============================] - 54s 33ms/step - loss: 0.3720 - acc: 0.8449- ETA: \n",
      "테스트 정확도: 0.8448814749717712\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('best_model.h5')\n",
    "print(f\"테스트 정확도: {loaded_model.evaluate(X_test, y_test)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_predict(new_sentence):\n",
    "    new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
    "    new_sentence = okt.morphs(new_sentence, stem=True)\n",
    "    new_sentence = [word for word in new_sentence if not word in stopwords]\n",
    "    encoded = tokenizer.texts_to_sequences([new_sentence])\n",
    "    pad_new = pad_sequences(encoded, maxlen = 30)\n",
    "    score = float(loaded_model.predict(pad_new))\n",
    "    if score > 0.5:\n",
    "        print(f\"{score*100} 확률로 긍정 리뷰입니다.\\n\")\n",
    "    else:\n",
    "        print(f\"{score*100} 확률로 부정 리뷰입니다.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.25915288925171 확률로 긍정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict(\"이 영화 개꿀잼 ㅋㅋㅋ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_labeling_df = pd.read_csv('./data/labeling.txt',sep='\\t',names=['sentence','sentiment','objective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>objective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7631</th>\n",
       "      <td>매일 사용하지 않는데 켜져 있으면 건전지 닳을까 봐</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>설령 저울위에 물건이 올려져 있더라도 분후에 꺼지게 되고 다시 사용하려면 전원버튼을...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7704</th>\n",
       "      <td>재료별로 도마를 각각 따로 사용하는게 좋다고해요</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>구매할 수 있는 링크는 아래에 첨부하겠습니다</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>네 가능합니다</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  sentiment  objective\n",
       "7631                       매일 사용하지 않는데 켜져 있으면 건전지 닳을까 봐        1.0        1.0\n",
       "2561  설령 저울위에 물건이 올려져 있더라도 분후에 꺼지게 되고 다시 사용하려면 전원버튼을...        1.0        1.0\n",
       "7704                         재료별로 도마를 각각 따로 사용하는게 좋다고해요        1.0        1.0\n",
       "242                            구매할 수 있는 링크는 아래에 첨부하겠습니다        1.0        1.0\n",
       "1701                                            네 가능합니다        1.0        1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_labeling_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_labeling_sentences = pre_labeling_df['sentence'].values\n",
    "pre_labeling_objectives = pre_labeling_df['objective'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존에 스타 전자저울 을 사용하고 있었는데 이게 어느날부터 상태가 안 좋더라구요\n",
      "3.5246580839157104 확률로 부정 리뷰입니다.\n",
      "\n",
      "건전지를 교체해보기도 하고 이래저래 만져봐도 도통 말을 듣지 않길래 정신건강을 위해 다시 저울을 구입했어요\n",
      "0.754159688949585 확률로 부정 리뷰입니다.\n",
      "\n",
      "원래는 스텐저울과 전자저울 두가지가 있었는데 스텐저울은 이미 한참 전에 망가졌어요\n",
      "24.691736698150635 확률로 부정 리뷰입니다.\n",
      "\n",
      "디자인보다는 튼튼한 것으로 당장 주문해도 내일 올 수 있는 것으로 단위로 측정할 수 있는 것이 필요했어요\n",
      "95.19228339195251 확률로 긍정 리뷰입니다.\n",
      "\n",
      "그래서 이마트몰 쓱배송으로 스타 전자 저울을 구입하게 되었어요\n",
      "87.69639730453491 확률로 긍정 리뷰입니다.\n",
      "\n",
      "기존에 사용하던 저울은 양푼을 올리면 넘게 무게를 먹고 들어가니깐 거의 단위로만 측정해야 했거든요\n",
      "68.66858005523682 확률로 긍정 리뷰입니다.\n",
      "\n",
      "별로 대단한게 아니더라도 만 측정 가능한 것과 까지 측정 가능한 것은 큰 차이가 있더라구요\n",
      "3.553035855293274 확률로 부정 리뷰입니다.\n",
      "\n",
      "올리다가 살짝 넘었는데 에러가 나면 저는 열불이 나더라구요\n",
      "5.864810943603516 확률로 부정 리뷰입니다.\n",
      "\n",
      "저울이라며이제 저울을 구입했으니 마음 편하게 조금 넘게도 올릴 수 있어서 행복해요\n",
      "99.51575994491577 확률로 긍정 리뷰입니다.\n",
      "\n",
      "제품 특징과 사용 방법은 박스 하단에 있더라구요\n",
      "47.846755385398865 확률로 부정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in pre_labeling_sentences[:10]:\n",
    "    print(sentence)\n",
    "    sentiment_predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_predict(new_sentence):\n",
    "    new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
    "    new_sentence = okt.morphs(new_sentence, stem=True)\n",
    "    new_sentence = [word for word in new_sentence if not word in stopwords]\n",
    "    encoded = tokenizer.texts_to_sequences([new_sentence])\n",
    "    pad_new = pad_sequences(encoded, maxlen = 30)\n",
    "    score = float(loaded_model.predict(pad_new))\n",
    "    if score > 0.5:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labeling_sentiments = [sentiment_predict(sentence) for sentence in pre_labeling_sentences]\n",
    "new_labeling_sentiments = np.array(new_labeling_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 2, 2, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 2, 2, 0,\n",
       "       2, 0, 2, 0, 0, 2, 0, 2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labeling_sentiments[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_X_train = pre_labeling_sentences[:298]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_y_train = pre_labeling_objectives[:298]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_y_train[np.isnan(obj_y_train)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_y_train[obj_y_train == 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_X_train = [re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\", obj) for obj in obj_X_train]\n",
    "obj_X_train = [okt.morphs(sentence) for sentence in obj_X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_X_train = [[word for word in obj if not word in stopwords] for obj in obj_X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokenizer = Tokenizer()\n",
    "new_tokenizer.fit_on_texts(pre_labeling_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_encoded = new_tokenizer.texts_to_sequences(obj_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pads = pad_sequences(new_encoded, maxlen=30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vocab_size = len(new_tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38186"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6611 - acc: 0.6513\n",
      "Epoch 00001: saving model to new_best_model.h5\n",
      "4/4 [==============================] - 14s 1s/step - loss: 0.6611 - acc: 0.6513 - val_loss: 0.6449 - val_acc: 0.7167\n",
      "Epoch 2/15\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6069 - acc: 0.6975\n",
      "Epoch 00002: saving model to new_best_model.h5\n",
      "4/4 [==============================] - 1s 360ms/step - loss: 0.6069 - acc: 0.6975 - val_loss: 0.5934 - val_acc: 0.7167\n",
      "Epoch 3/15\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5833 - acc: 0.7101\n",
      "Epoch 00003: saving model to new_best_model.h5\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 0.5833 - acc: 0.7101 - val_loss: 0.6276 - val_acc: 0.7167\n",
      "Epoch 4/15\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5095 - acc: 0.7689\n",
      "Epoch 00004: saving model to new_best_model.h5\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.5095 - acc: 0.7689 - val_loss: 0.5856 - val_acc: 0.7167\n",
      "Epoch 5/15\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4018 - acc: 0.7353\n",
      "Epoch 00005: saving model to new_best_model.h5\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.4018 - acc: 0.7353 - val_loss: 0.6365 - val_acc: 0.7167\n",
      "Epoch 6/15\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3197 - acc: 0.9160\n",
      "Epoch 00006: saving model to new_best_model.h5\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 0.3197 - acc: 0.9160 - val_loss: 0.7937 - val_acc: 0.7000\n",
      "Epoch 7/15\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2207 - acc: 0.9412\n",
      "Epoch 00007: saving model to new_best_model.h5\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.2207 - acc: 0.9412 - val_loss: 0.9728 - val_acc: 0.7000\n",
      "Epoch 8/15\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1943 - acc: 0.9412\n",
      "Epoch 00008: saving model to new_best_model.h5\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 0.1943 - acc: 0.9412 - val_loss: 0.7894 - val_acc: 0.6833\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "new_model = Sequential()\n",
    "new_model.add(Embedding(new_vocab_size, embedding_dim))\n",
    "new_model.add(LSTM(hidden_units))\n",
    "new_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('new_best_model.h5', monitor='val_acc', mode='max', verbose=1, save_bset_only=True)\n",
    "\n",
    "new_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "new_history = new_model.fit(new_pads, obj_y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_loaded_model = load_model('new_best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_sentiment_predict(new_sentence):\n",
    "    new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
    "    new_sentence = okt.morphs(new_sentence, stem=True)\n",
    "    new_sentence = [word for word in new_sentence if not word in stopwords]\n",
    "    encoded = tokenizer.texts_to_sequences([new_sentence])\n",
    "    pad_new = pad_sequences(encoded, maxlen = 30)\n",
    "    score = float(new_loaded_model.predict(pad_new))\n",
    "    if score > 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labeling_objectives = [new_sentiment_predict(sentence) for sentence in pre_labeling_sentences]\n",
    "new_labeling_objectives = np.array(new_labeling_objectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/new_labeling.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "    for sentence, sentiment, objective in zip(pre_labeling_sentences, new_labeling_sentiments, new_labeling_objectives):\n",
    "        f.write(f\"{sentence}\\t{sentiment}\\t{objective}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X, y, output_dim, optimizer_function, loss_function, activation_function):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(50000, embedding_dim, input_length=X.shape[1]))\n",
    "    model.add(LSTM(hidden_units))\n",
    "    model.add(Dense(output_dim, activation=activation_function))\n",
    "\n",
    "    model.compile(optimizer=optimizer_function, loss=loss_function, metrics=['acc'])\n",
    "    history = model.fit(X, y, epochs=15, batch_size=64, validation_split=0.2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_X_data(X,labeling_index):\n",
    "    X = X[:labeling_index]\n",
    "    X = [re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\",sent) for sent in X]\n",
    "    X = [okt.morphs(sent, stem=True) for sent in X]\n",
    "    X = [sent for sent in X if not sent in stopwords]\n",
    "    X = new_tokenizer.texts_to_sequences(X)\n",
    "    X = pad_sequences(X, maxlen=50)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_y_data(y, labeling_index):\n",
    "    y = y[:labeling_index]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_path(file_path):\n",
    "    df = pd.read_csv(file_path, sep='\\t' ,names=['sentence','sentiment','objective'])\n",
    "    sentences = df['sentence'].values\n",
    "    sentiments = df['sentiment'].values\n",
    "    objectives = df['objective'].values\n",
    "    return (sentences, sentiments, objectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, sentiments, objectives = get_data_from_path(\"./data/new_labeling.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sentences = make_X_data(sentences,504)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sentiments = make_y_data(sentiments,504)\n",
    "training_objectives = make_y_data(objectives,504)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 2., 2., 2., 0., 0., 2., 0., 0., 2., 0., 2., 0., 2., 2.,\n",
       "       0., 0., 2., 2., 0., 2., 0., 2., 0., 0., 2., 2., 0., 1., 2., 2., 0.,\n",
       "       0., 2., 0., 0., 0., 2., 2., 2., 2., 0., 2., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 2., 2., 0., 2., 2., 0., 0., 2., 0., 0., 0., 0., 2., 2.,\n",
       "       2., 0., 0., 2., 0., 0., 0., 0., 0., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 1., 1., 1., 1., 2., 2., 2., 1., 2., 2., 2., 2., 2., 1., 1., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 1., 1., 1., 2., 1., 1., 2., 2., 2., 1.,\n",
       "       1., 2., 1., 1., 1., 2., 1., 0., 2., 1., 2., 1., 1., 2., 1., 1., 2.,\n",
       "       2., 1., 2., 0., 2., 2., 1., 2., 2., 2., 1., 1., 2., 2., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 2., 2., 2., 2., 1.,\n",
       "       1., 1., 1., 1., 1., 2., 2., 0., 2., 0., 0., 1., 2., 1., 2., 1., 0.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 1., 1., 2., 1., 2., 1., 2., 1., 2., 2.,\n",
       "       1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 2.,\n",
       "       0., 2., 1., 2., 2., 0., 1., 2., 1., 0., 2., 2., 2., 2., 1., 2., 2.,\n",
       "       2., 1., 1., 0., 1., 1., 1., 0., 0., 2., 0., 0., 2., 1., 2., 2., 2.,\n",
       "       2., 2., 0., 2., 2., 2., 2., 2., 2., 2., 2., 2., 1., 2., 1., 2., 1.,\n",
       "       1., 0., 1., 2., 2., 2., 2., 2., 2., 1., 1., 2., 1., 1., 2., 2., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 2., 1., 2., 1., 2., 1., 1., 2., 2., 0., 1.,\n",
       "       1., 1., 1., 0., 0., 2., 2., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 2., 2., 2., 1., 2., 1., 2., 2., 1., 2., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 2., 2., 1., 1., 2., 2., 1., 1., 1., 1., 2., 1., 1., 2.,\n",
       "       2., 1., 1., 2., 2., 1., 1., 1., 1., 1., 2., 2., 1., 0., 1., 1., 2.,\n",
       "       2., 1., 1., 2., 2., 1., 1., 2., 2., 2., 0., 1., 2., 2., 1., 1., 2.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 2., 2., 1., 2.,\n",
       "       2., 1., 1., 1., 1., 2., 1., 2., 2., 2., 2., 2., 2., 2., 2., 1., 2.,\n",
       "       2., 1., 1., 2., 1., 1., 1., 2., 1., 1., 1., 2., 2., 2., 1., 2., 1.,\n",
       "       1., 1., 1., 1., 2., 2., 1., 1., 1., 1., 2., 1., 1., 1., 0., 1., 2.,\n",
       "       1., 2., 2., 2., 2., 2., 1., 0., 2., 2., 2., 2., 2., 1., 1., 0., 2.,\n",
       "       2., 1., 2., 2., 1., 2., 1., 2., 1., 1., 1., 1., 1., 1., 2., 1., 1.,\n",
       "       1., 1., 2., 0., 0., 1., 2., 1., 1., 2., 0.])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sentiments[np.isnan(training_sentiments)] = 1\n",
    "training_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_objectives[np.isnan(training_objectives)] = 1\n",
    "training_objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,model):\n",
    "    return np.argmax(model.predict([sentence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_y_train(y, num_of_classes):\n",
    "    new_y = np.zeros((y.shape[0], num_of_classes))\n",
    "    for idx, value in enumerate(y):\n",
    "        value = int(value)\n",
    "        new_y[idx][value] = 1\n",
    "    return new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sentiments = get_multi_y_train(sentiments,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "7/7 [==============================] - 4s 324ms/step - loss: 1.0840 - acc: 0.4243 - val_loss: 0.9848 - val_acc: 0.5941\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 1.0365 - acc: 0.4938 - val_loss: 0.9503 - val_acc: 0.4554\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 1.0137 - acc: 0.4318 - val_loss: 0.9587 - val_acc: 0.4455\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.9825 - acc: 0.4864 - val_loss: 0.9300 - val_acc: 0.5743\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 1s 204ms/step - loss: 0.9296 - acc: 0.6501 - val_loss: 0.9165 - val_acc: 0.6535\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 2s 215ms/step - loss: 0.8189 - acc: 0.6526 - val_loss: 1.2868 - val_acc: 0.6040\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 1s 174ms/step - loss: 0.6994 - acc: 0.7270 - val_loss: 1.1889 - val_acc: 0.6238\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 1s 165ms/step - loss: 0.5221 - acc: 0.8164 - val_loss: 1.3062 - val_acc: 0.5941\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 1s 167ms/step - loss: 0.4189 - acc: 0.8809 - val_loss: 1.7103 - val_acc: 0.6139\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.3805 - acc: 0.8883 - val_loss: 1.4493 - val_acc: 0.5545\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.3244 - acc: 0.9330 - val_loss: 1.6415 - val_acc: 0.5545\n",
      "Epoch 12/15\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.2522 - acc: 0.9429 - val_loss: 1.5501 - val_acc: 0.6238\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 1s 209ms/step - loss: 0.1808 - acc: 0.9479 - val_loss: 1.8265 - val_acc: 0.6040\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 1s 202ms/step - loss: 0.1429 - acc: 0.9677 - val_loss: 1.8602 - val_acc: 0.6040\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 2s 252ms/step - loss: 0.1077 - acc: 0.9653 - val_loss: 2.2096 - val_acc: 0.5842\n"
     ]
    }
   ],
   "source": [
    "sentiment_model = training(training_sentences, new_sentiments, 3, 'adam', 'categorical_crossentropy', \"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sentences = make_X_data(sentences,sentences.shape[0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sentiments = sentiment_model.predict(predicted_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sentiments = np.array([np.argmax(sent) for sent in predicted_sentiments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7961,)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_sentiments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "7/7 [==============================] - 8s 464ms/step - loss: 0.6626 - acc: 0.6948 - val_loss: 0.5034 - val_acc: 0.8119\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 1s 205ms/step - loss: 0.6240 - acc: 0.7072 - val_loss: 0.5441 - val_acc: 0.8119\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 2s 218ms/step - loss: 0.5576 - acc: 0.7072 - val_loss: 0.4721 - val_acc: 0.8119\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 2s 229ms/step - loss: 0.5214 - acc: 0.7097 - val_loss: 0.5277 - val_acc: 0.8218\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 1s 197ms/step - loss: 0.4673 - acc: 0.7519 - val_loss: 0.4707 - val_acc: 0.8119\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 1s 217ms/step - loss: 0.3851 - acc: 0.8139 - val_loss: 0.4828 - val_acc: 0.7723\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 1s 166ms/step - loss: 0.3300 - acc: 0.8859 - val_loss: 0.5393 - val_acc: 0.6931\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.2921 - acc: 0.9082 - val_loss: 0.4950 - val_acc: 0.7030\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 1s 186ms/step - loss: 0.2267 - acc: 0.9256 - val_loss: 0.5431 - val_acc: 0.7228\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 0.1881 - acc: 0.9404 - val_loss: 0.5984 - val_acc: 0.6931\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 1s 218ms/step - loss: 0.1854 - acc: 0.9355 - val_loss: 0.5849 - val_acc: 0.6436\n",
      "Epoch 12/15\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.1406 - acc: 0.9578 - val_loss: 0.6395 - val_acc: 0.6238\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.1123 - acc: 0.9801 - val_loss: 0.7382 - val_acc: 0.6238\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 2s 255ms/step - loss: 0.0864 - acc: 0.9752 - val_loss: 0.7710 - val_acc: 0.5743\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 1s 209ms/step - loss: 0.0671 - acc: 0.9851 - val_loss: 0.8021 - val_acc: 0.6733\n"
     ]
    }
   ],
   "source": [
    "objective_model = training(training_sentences, training_objectives, 1, 'rmsprop', 'binary_crossentropy', \"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9994261 ],\n",
       "       [0.999744  ],\n",
       "       [0.99717903],\n",
       "       ...,\n",
       "       [0.9844115 ],\n",
       "       [0.9841026 ],\n",
       "       [0.9971274 ]], dtype=float32)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_objectives = objective_model.predict(predicted_sentences)\n",
    "predicted_objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_objectives = predicted_objectives.flatten()\n",
    "predicted_objectives = np.array([1 if score>=0.5 else 0 for score in predicted_objectives])\n",
    "predicted_objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_labeling(file_path, data):\n",
    "    sentences, sentiments, objectives = data\n",
    "    with open(file_path,\"w\",encoding=\"utf-8\") as f:\n",
    "        for sentence, sentiment, objective in zip(sentences, sentiments, objectives):\n",
    "            f.write(f\"{sentence}\\t{sentiment}\\t{objective}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_labeling(\"./data/new_labeling2.txt\",(sentences,predicted_sentiments,predicted_objectives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cdfda138ad5bcab69f3640f79512bb442e262eb8606e188c4172350e36929680"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
