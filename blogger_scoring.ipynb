{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "blogger_scoring.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNsTDwFh5TiJ/UoHRkJXq74",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zambbo/BERT-blog-sentiment-analysis/blob/master/blogger_scoring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr4sv9OKkAcS"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "BwHKSaDmkkqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0')"
      ],
      "metadata": {
        "id": "YbyCK1ELkw_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ipm6VVCkkylF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 셋을 BERT모델에 알맞은 형태로 변경\n",
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "NDptrfY7k1Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT 모델\n",
        "#sentiment predict를 위해서는 num_classes를 3으로 설정해준다\n",
        "#objective/subjective predict를 위해서는 num_classes를 2로 설정해준다.\n",
        "#default는 3으로 되어있다\n",
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=3,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "\n",
        "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "        \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "    \n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "\n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "metadata": {
        "id": "7Rr07MNDk3vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kobert import get_tokenizer\n",
        "from kobert import get_pytorch_kobert_model"
      ],
      "metadata": {
        "id": "DQIPxRVMk82V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KoBERT 모델과 KoBERT vocabulary를 다운받는다.\n",
        "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")"
      ],
      "metadata": {
        "id": "onQkBidGlzxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_model = BERTClassifier(bertmodel, num_classes=3, dr_rate=0.5).to(device)\n",
        "subjective_model = BERTClassifier(bertmodel, num_classes=2, dr_rate=0.5).to(device)"
      ],
      "metadata": {
        "id": "BEpvgyJDl6ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_path = '/content/drive/MyDrive/dataset/sentiment_model.pt'\n",
        "subj_path = '/content/drive/MyDrive/dataset/subjetive_model.pt'"
      ],
      "metadata": {
        "id": "4I6QuLBel8-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_model.load_state_dict(torch.load(sent_path))\n",
        "subjective_model.load_state_dict(torch.load(subj_path))"
      ],
      "metadata": {
        "id": "h5pCgnBll-zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_model.eval()\n",
        "subjective_model.eval()"
      ],
      "metadata": {
        "id": "zsfHOZUNmAmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "file_path = \"/content/drive/MyDrive/dataset/rilrastory.csv\"\n",
        "df = pd.read_csv(file_path, index_col = 0)\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "MHxDztfEmCWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime \n",
        "def row_func(row):\n",
        "    year, month, day, _ = row.split(\".\")\n",
        "    return datetime.date(int(year), int(month), int(day))"
      ],
      "metadata": {
        "id": "H4vlLeLPqFGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dates = df['Posting Date']\n",
        "dates = dates.apply(row_func)"
      ],
      "metadata": {
        "id": "J3o4vpiapKlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Posting Date'] = dates\n",
        "df = df.sort_values(by=['Posting Date'], ascending=False)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "RYNiQM6fps7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[:90]"
      ],
      "metadata": {
        "id": "5l2XhQEyqVbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kss\n",
        "import kss"
      ],
      "metadata": {
        "id": "j9htDVozsX41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def preprocessing(sentence):\n",
        "    sentence = re.sub(\"[^ ㄱ-ㅎ가-힣a-zA-Z0-9]\",\"\",sentence)\n",
        "    return sentence\n",
        "preprocessing(df.iloc[0,:]['Post'])"
      ],
      "metadata": {
        "id": "1SWrCUcps0Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posts = df['Post']\n",
        "posts = posts.apply(preprocessing)\n",
        "df['Post'] = posts\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "cqXWIvg9tOun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_post(post):\n",
        "    sentences = []\n",
        "    for sentence in kss.split_sentences(post):\n",
        "        sentences.append(sentence)\n",
        "    return sentences\n",
        "split_post(df.iloc[0,:]['Post'])"
      ],
      "metadata": {
        "id": "TJZW1i6tte7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posts = df['Post'].apply(split_post)\n",
        "posts[:3]"
      ],
      "metadata": {
        "id": "X8T2X1TKtjYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 64\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ],
      "metadata": {
        "id": "cUqYXGYZwvz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bertToTorch(_data, device):\n",
        "    token_ids, valid_length, segment_ids, label = _data\n",
        "    token_ids = torch.tensor([token_ids])\n",
        "    segment_ids = torch.tensor([segment_ids])\n",
        "    token_ids = token_ids.long().to(device)\n",
        "    segment_ids = segment_ids.long().to(device)\n",
        "    valid_length = torch.IntTensor([valid_length.item()])\n",
        "    return token_ids, valid_length, segment_ids"
      ],
      "metadata": {
        "id": "oCCfMf1dw53w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def toBertDataset(post):\n",
        "    post = [[sent,'1'] for sent in post]\n",
        "    bertdataset = BERTDataset(post, 0, 1, tok, max_len, True, False)\n",
        "    return bertdataset\n",
        "toBertDataset(posts.iloc[0])"
      ],
      "metadata": {
        "id": "nS4tCpeVutqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scoring_func(_predicted):\n",
        "    predicted = _predicted.cpu().detach().numpy()\n",
        "    predicted_value = np.argmax(predicted)\n",
        "    return predicted_value\n"
      ],
      "metadata": {
        "id": "1eZAnnj2yPKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_label(_bertdataset, _model, score_func):\n",
        "    predicted_labels = []\n",
        "    for bs in _bertdataset:\n",
        "        token_ids, valid_length, segment_ids = bertToTorch(bs, device)\n",
        "        predicted = _model(token_ids, valid_length, segment_ids)\n",
        "        predicted_value = score_func(predicted)\n",
        "        predicted_labels.append(predicted_value)\n",
        "    \n",
        "    predicted_labels = predicted_labels\n",
        "    return predicted_labels"
      ],
      "metadata": {
        "id": "klrh915nyNde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posts_sentiments = []\n",
        "posts_subjectives = []\n",
        "\n",
        "for post in posts:\n",
        "\n",
        "    post_bert = toBertDataset(post)\n",
        "    predicted_sentiments = predict_label(post_bert, sentiment_model, scoring_func)\n",
        "    predicted_subjectives = predict_label(post_bert, subjective_model, scoring_func)\n",
        "\n",
        "    posts_sentiments.append(predicted_sentiments)\n",
        "    posts_subjectives.append(predicted_subjectives)\n",
        "posts_sentiments[:2]"
      ],
      "metadata": {
        "id": "p-BvH2vZvm3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posts = posts.values\n",
        "after_predicted = []\n",
        "for post, sentiments, subjectives in zip(posts, posts_sentiments, posts_subjectives):\n",
        "    after_predicted.append([(sentence, sentiment, subjective) for sentence, sentiment, subjective in zip(post, sentiments, subjectives)])\n",
        "after_predicted[0]"
      ],
      "metadata": {
        "id": "IhEZyHhRznIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['AP'] = after_predicted\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "EuXloFtu0ksp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/dataset/test_after_blogger.csv'\n",
        "df.to_csv(file_path)"
      ],
      "metadata": {
        "id": "qFvGqMWq2kUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lcWh_1QxNqGe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}