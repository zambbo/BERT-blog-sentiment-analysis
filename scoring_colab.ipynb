{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scoring_colab.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMkPdWsFzftEj9pVlnF8OqL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zambbo/BERT-blog-sentiment-analysis/blob/master/scoring_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HRvgNpDBagw"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "A6m3rJIZBfwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0')"
      ],
      "metadata": {
        "id": "sB79tlAQBhV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "noE1-gXuBsf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "HLgK9Z9wBu5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClassifier_sent(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=3,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier_sent, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "\n",
        "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "        \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "    \n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "\n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "metadata": {
        "id": "MivRvPhfCPAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClassifier_subj(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=2,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier_subj, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "\n",
        "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "        \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "    \n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "\n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "metadata": {
        "id": "9ouylqYqDbdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kobert import get_tokenizer\n",
        "from kobert import get_pytorch_kobert_model"
      ],
      "metadata": {
        "id": "cx-Ys6YBCeg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")"
      ],
      "metadata": {
        "id": "1nt9JC0uCTEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_model = BERTClassifier_sent(bertmodel, dr_rate=0.5).to(device)\n",
        "subjective_model = BERTClassifier_subj(bertmodel, dr_rate=0.5).to(device)"
      ],
      "metadata": {
        "id": "uCUfQCl4CbBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_path = '/content/drive/MyDrive/dataset/sentiment_model.pt'\n",
        "subj_path = '/content/drive/MyDrive/dataset/subjetive_model.pt'"
      ],
      "metadata": {
        "id": "fuWSv9-ACld4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_model.load_state_dict(torch.load(sent_path))\n",
        "subjective_model.load_state_dict(torch.load(subj_path))"
      ],
      "metadata": {
        "id": "w8gaJOeUC6fB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_model.eval()\n",
        "subjective_model.eval()"
      ],
      "metadata": {
        "id": "UGCkoTB6DBXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/dataset/미니어처.csv',index_col=0)\n",
        "df.sample(3)"
      ],
      "metadata": {
        "id": "KuXIqMqYDi06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = df[:5]"
      ],
      "metadata": {
        "id": "n7fA4MUsD7R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kss"
      ],
      "metadata": {
        "id": "jpozB4ZqEAo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocessing_sentence(sentence):\n",
        "    sent = re.sub(\"[^ ㄱ-ㅎ가-힣a-zA-Z1-9]\", \"\", sentence)\n",
        "    return sent"
      ],
      "metadata": {
        "id": "xPnwEksTEBa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posts = [preprocessing_sentence(sent) for sent in test_df['Post'].values]\n",
        "posts[0]"
      ],
      "metadata": {
        "id": "kyCocsn5EQIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kss\n",
        "post_sentences = []\n",
        "\n",
        "for post in posts:\n",
        "    sents = [sent for sent in kss.split_sentences(post)]\n",
        "    post_sentences.append(sents)\n",
        "post_sentences[0]"
      ],
      "metadata": {
        "id": "B7bD-p6aEann"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence2bertdataset(posts):\n",
        "    ret_sentences = []\n",
        "    for post in posts:\n",
        "        ret_sentences.append([[sent,'1'] for sent in post])\n",
        "    return ret_sentences"
      ],
      "metadata": {
        "id": "OPjB6ZMHE5t_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_post_sentences = sentence2bertdataset(post_sentences)"
      ],
      "metadata": {
        "id": "8CENow3tFbNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_post_sentences[0]"
      ],
      "metadata": {
        "id": "GVR-XBx1IiBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 64\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ],
      "metadata": {
        "id": "ECYOrskfH_zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = [BERTDataset(sentences, 0, 1, tok, max_len, True, False) for sentences in new_post_sentences]\n",
        "test_input = [torch.utils.data.DataLoader(test_s, batch_size=1, num_workers=5) for test_s in test_set]"
      ],
      "metadata": {
        "id": "9egitztzGwnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_analysis(output_tensor):\n",
        "    output_tensor = output_tensor.cpu().detach().numpy()\n",
        "    argmax = np.argmax(output_tensor)\n",
        "    if argmax == 2:\n",
        "        return '긍정'\n",
        "    if argmax == 1:\n",
        "        return '중립'\n",
        "    if argmax == 0:\n",
        "        return '부정'"
      ],
      "metadata": {
        "id": "echVLk53IFqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def subjective_analysis(output_tensor):\n",
        "    output_tensor = output_tensor.cpu().detach().numpy()\n",
        "    argmax = np.argmax(output_tensor)\n",
        "    if argmax == 1:\n",
        "        return '객관'\n",
        "    if argmax == 0:\n",
        "        return '주관'"
      ],
      "metadata": {
        "id": "k3dHX6ODILEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for test in test_set[0]:\n",
        "    a,b,c,d = test\n",
        "    print(a,b,c,d)\n",
        "    break"
      ],
      "metadata": {
        "id": "1qWn04HELxhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neutral = 0\n",
        "positive = 0\n",
        "negative = 0\n",
        "objective = 0\n",
        "subjective = 0\n",
        "for post_idx, test_post in enumerate(test_set):\n",
        "    print(f\"{post_idx+1}-----------------------------------------------------------------------\")\n",
        "    if post_idx == 1: break \n",
        "    for sent_idx, test in enumerate(test_post):\n",
        "        token_ids, valid_length, segment_ids, label = test\n",
        "        token_ids = torch.Tensor([token_ids])\n",
        "        segment_ids = torch.Tensor([segment_ids])\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length = torch.IntTensor([valid_length.item()])\n",
        "        sent_out = sentiment_model(token_ids, valid_length, segment_ids)\n",
        "        subj_out = subjective_model(token_ids, valid_length, segment_ids)\n",
        "        print(f\"{post_sentences[post_idx][sent_idx]} {sentiment_analysis(sent_out)} {subjective_analysis(subj_out)}\")\n",
        "        sentiment_result = sentiment_analysis(sent_out)\n",
        "        subjective_result = subjective_analysis(subj_out)\n",
        "        if sentiment_result == '긍정':\n",
        "            positive += 1\n",
        "        if sentiment_result == '중립':\n",
        "            neutral += 1\n",
        "        if sentiment_result == '부정':\n",
        "            negative += 1\n",
        "        if subjective_result == '객관':\n",
        "            objective += 1\n",
        "        if subjective_result == '주관':\n",
        "            subjective += 1\n",
        "print(f\"긍정:{positive} 중립:{neutral} 부정:{negative} 객관:{objective} 주관:{subjective}\")"
      ],
      "metadata": {
        "id": "3WSDzy3HJVmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (token_ids, valid_length, segment_ids, label) in enumerate(test_input[0]):\n",
        "    token_ids = token_ids.long().to(device)\n",
        "    segment_ids = segment_ids.long().to(device)\n",
        "    valid_length = valid_length\n",
        "    print(token_ids)\n",
        "    print(valid_length)\n",
        "    print(type(valid_length))\n",
        "    out = sentiment_model(token_ids,valid_length,segment_ids)\n",
        "    print(sentiment_analysis(out))"
      ],
      "metadata": {
        "id": "fKiRBzPoXfUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_sentences[0]"
      ],
      "metadata": {
        "id": "kxpx9lsYZbly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vHAuUZ8VcoFj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}